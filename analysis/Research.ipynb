{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Steven Sheffey\n",
    "# This file is part of packet_captor_sakura.\n",
    "#\n",
    "# packet_captor_sakura is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# packet_captor_sakura is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with packet_captor_sakura.  If not, see <https:# www.gnu.org/licenses/>.\n",
    "import datetime\n",
    "import gzip\n",
    "from itertools import permutations\n",
    "import logging\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "import typing\n",
    "\n",
    "from IPython.display import display, Math, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from sklearn import utils as sklearn_utils\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm_notebook as tqdm, tnrange\n",
    "\n",
    "# Set up the logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Set up matplotlib magic\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(data_root):\n",
    "    def load_data(filename: str):\n",
    "        return pd.read_json(filename, lines=True) \\\n",
    "            .rename(index=str, columns={\n",
    "                \"c\": \"class\",\n",
    "                \"u\": \"url\",\n",
    "                \"f\": \"is_first_of_type\",\n",
    "                \"pl\": \"packet_length_bins\",\n",
    "                \"iaf\": \"interarrival_time_from_client_bins\",\n",
    "                \"iat\": \"interarrival_time_to_client_bins\"\n",
    "            })\n",
    "    def filter_firsts(df):\n",
    "        return df.loc[df[\"is_first_of_type\"] == False]\n",
    "\n",
    "    def reorder_columns(df):\n",
    "        return df[[\"packet_length_bins\", \"interarrival_time_from_client_bins\", \"interarrival_time_to_client_bins\"]]\n",
    "\n",
    "    def to_numpy(df):\n",
    "        return np.array(df.values.tolist(), dtype=np.float32)\n",
    "\n",
    "\n",
    "    # Load datasets\n",
    "    normal_data = load_data(data_root / \"normal.json.gz\")\n",
    "    tor_data = load_data(data_root / \"tor.json.gz\")\n",
    "\n",
    "    # Print initial dataset size\n",
    "    print(f\"Normal entries: {len(normal_data.index)}\")\n",
    "    print(f\"Tor entries: {len(tor_data.index)}\")\n",
    "    \n",
    "    filter_first = False\n",
    "    if filter_first:\n",
    "        normal_data = filter_firsts(normal_data)\n",
    "        tor_data = filter_firsts(tor_data)\n",
    "        print(\"Normal entries after filter: {}\".format(normal_data.count()))\n",
    "        print(\"Tor entries after filter: {}\".format(tor_data.count()))\n",
    "    \n",
    "    normal_data = reorder_columns(normal_data)\n",
    "    tor_data = reorder_columns(tor_data)\n",
    "    \n",
    "    normal_data = to_numpy(normal_data)\n",
    "    tor_data = to_numpy(tor_data)\n",
    "    print(f\"Normal data shape: {normal_data.shape}\")\n",
    "    print(f\"Tor data shape: {tor_data.shape}\")\n",
    "\n",
    "    # Equalize samples\n",
    "    min_samples = min(tor_data.shape[0], normal_data.shape[0])\n",
    "    normal_data = normal_data[:min_samples]\n",
    "    tor_data = tor_data[:min_samples]\n",
    "\n",
    "    # Print dimensions\n",
    "    print(f\"Normal data shape after classes balanced: {normal_data.shape}\")\n",
    "    print(f\"Tor data shape after classes balanced: {tor_data.shape}\")\n",
    "    return normal_data, tor_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate figures for initial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_DIR = Path('figures')\n",
    "\n",
    "def generate_figures(normal_data, tor_data, figure_dir, figure_size):\n",
    "    sns.set()\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.rcParams.update({'savefig.dpi': 1200})\n",
    "    ps_bins = list(map(str, list(range(0,100+1, 10)) + list(range(200,1000+1,100)) + list(range(2000,10000+1,1000)) + ['∞']))\n",
    "    ia_bins = list(map(str, list(range(0,10+1)) + list(range(20,100+1,10)) + list(range(200,1000+1,100)) + ['∞']))\n",
    "\n",
    "    # Average fields for each dataset and feature\n",
    "    data = {\n",
    "        \"x\": [i + 0.5 for i in range(29)],\n",
    "        \"tor_ps\":     tor_data[:,0,:].mean(axis=0),\n",
    "        \"normal_ps\":  normal_data[:,0,:].mean(axis=0),\n",
    "        \"tor_iaf\":    tor_data[:,1,:].mean(axis=0),\n",
    "        \"normal_iaf\": normal_data[:,1,:].mean(axis=0),\n",
    "        \"tor_iat\":    tor_data[:,2,:].mean(axis=0),\n",
    "        \"normal_iat\": normal_data[:,2,:].mean(axis=0),\n",
    "    }\n",
    "    # Start plotting packet sizes\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    sns.lineplot(\"x\", \"tor_ps\", label=\"Meek\", data=data)\n",
    "    ax = sns.lineplot(\"x\", \"normal_ps\", label=\"HTTPS\", data=data)\n",
    "    ax.legend()\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='26') # for legend text\n",
    "    ax.set_xlabel(\"TCP Payload length (bytes)\", fontsize=28)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=28)\n",
    "    ax.set_xticks(range(30))\n",
    "    ax.set_xticklabels(ps_bins, rotation=90)\n",
    "    ax.tick_params(labelsize=22)\n",
    "    fig.savefig(figure_dir / 'initial-features-packet-size.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Start plotting interarrival from client\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    sns.lineplot(\"x\", \"tor_iaf\", label=\"Meek\", data=data)\n",
    "    ax = sns.lineplot(\"x\", \"normal_iaf\", label=\"HTTPS\", data=data)\n",
    "    ax.legend()\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='26') # for legend text\n",
    "    ax.set_xlabel(\"Inter-arrival time from client (ms)\", fontsize=28)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=28)\n",
    "    ax.set_xticks(range(30))\n",
    "    ax.set_xticklabels(ia_bins, rotation=90)\n",
    "    ax.tick_params(labelsize=22)\n",
    "    fig.savefig(figure_dir / 'initial-features-iaf.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Start plotting interarrival to client\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    sns.lineplot(\"x\", \"tor_iat\", label=\"Meek\", data=data)\n",
    "    ax = sns.lineplot(\"x\", \"normal_iat\", label=\"HTTPS\", data=data)\n",
    "    ax.legend()\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='26') # for legend text\n",
    "    ax.set_xlabel(\"Inter-arrival time to client (ms)\", fontsize=28)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=28)\n",
    "    ax.set_xticks(range(30))\n",
    "    ax.set_xticklabels(ia_bins, rotation=90)\n",
    "    ax.tick_params(labelsize=22)\n",
    "    fig.savefig(figure_dir / 'initial-features-iat.pdf', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, **config):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # Get hidden layer_size\n",
    "        hidden_layer_size = config.get(\"hidden_layer_size\", 64)\n",
    "        # Hidden layer\n",
    "        self.fc1 = nn.Linear(np.product(input_dim), hidden_layer_size)\n",
    "        # Output fake/real\n",
    "        self.src_out = nn.Linear(hidden_layer_size, 1)\n",
    "        # Output class\n",
    "        self.class_out = nn.Linear(hidden_layer_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(-2)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        # x = F.leaky_relu(self.fc2(x))\n",
    "        return self.src_out(x), self.class_out(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, **config):\n",
    "        super(Generator, self).__init__()\n",
    "        # Store input dimensions\n",
    "        self.input_dim = input_dim\n",
    "        # Get hidden layer_size\n",
    "        hidden_layer_size = config.get(\"hidden_layer_size\", 128)\n",
    "        # Hidden layer\n",
    "        self.fc1 = nn.Linear(np.product(input_dim) + 1, hidden_layer_size)\n",
    "        # Output layer\n",
    "        self.out = nn.Linear(hidden_layer_size, np.product(input_dim))\n",
    "        \n",
    "\n",
    "    def forward(self, input_data, target_class):\n",
    "        x = torch.cat((input_data.flatten(-2), target_class.view(target_class.shape[0], 1).float()), 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.out(x))\n",
    "        return x.view(-1, *self.input_dim)\n",
    "\n",
    "def train_gan(x, y, **config):\n",
    "    \"\"\"\n",
    "    Trains a StarGAN to build a discriminator that classifies traffic,\n",
    "    and a generator that modifies traffic to trick the discriminator\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = {}\n",
    "    # Training device\n",
    "    device = torch.device(config.get('device', 'cpu'))\n",
    "    # Find the input dimensions\n",
    "    input_dim = x.shape[-2:]\n",
    "    # Number of classes\n",
    "    num_classes = 2\n",
    "    # Hyperparameters\n",
    "    # Minibatch size\n",
    "    batch_size = config.get(\"batch_size\", 16)\n",
    "    # Default number of iterations is 1 epoch\n",
    "    num_iters = config.get(\"num_iters\", input_dim[0] // batch_size)\n",
    "    # Generator learning rate\n",
    "    g_lr = config.get(\"g_lr\", 0.0001)\n",
    "    # Discriminator learning rate\n",
    "    d_lr = config.get(\"d_lr\", 0.0001)\n",
    "    # Betas for optimizer\n",
    "    beta1 = config.get(\"beta1\", 0.5)\n",
    "    beta2 = config.get(\"beta2\", 0.999)\n",
    "    # Loss weights\n",
    "    lambda_gp = config.get(\"lambda_gp\", 10)\n",
    "    lambda_cls = config.get(\"lambda_cls\", 1)\n",
    "    lambda_rec = config.get(\"lambda_rec\", 10)\n",
    "    lambda_del = config.get(\"lambda_del\", 10)\n",
    "    # Number of iterations to train discriminator before training generator\n",
    "    n_critic = config.get(\"n_critic\", 5)\n",
    "    # Number of iterations to wait before logging loss\n",
    "    log_step = config.get(\"log_step\", 100)\n",
    "    # Expected amount of improvement before quitting\n",
    "    improvement_amount = config.get(\"improvement_amount\", 1e-2)\n",
    "    # Number of iterations to wait to check for improvement\n",
    "    improvement_patience = config.get(\"improvement_patience\", 1000)\n",
    "\n",
    "    # Initialize models\n",
    "    discriminator = Discriminator(input_dim, num_classes).to(device)\n",
    "    generator = Generator(input_dim, num_classes).to(device)\n",
    "    \n",
    "    # Initialize optimizers\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), g_lr, [beta1, beta2])\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), d_lr, [beta1, beta2])\n",
    "    \n",
    "    # Convert the training set to tensors\n",
    "    x_tensor = torch.from_numpy(x).to(device)\n",
    "    y_tensor = torch.from_numpy(y).to(device)\n",
    "    \n",
    "    # Create a dataset from the training tensors\n",
    "    dataset = TensorDataset(x_tensor, y_tensor)\n",
    "    # Abstract tensor data loading\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    data_iter = iter(data_loader)\n",
    "\n",
    "    # Define our classification loss function\n",
    "    def classification_loss(logit, target):\n",
    "        return F.cross_entropy(logit, target)\n",
    "    \n",
    "    # Define our gradient penalty\n",
    "    def gradient_penalty(y, x):\n",
    "        \"\"\"Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.\"\"\"\n",
    "        weight = torch.ones(y.size()).to(device)\n",
    "        dydx = torch.autograd.grad(outputs=y,\n",
    "                                   inputs=x,\n",
    "                                   grad_outputs=weight,\n",
    "                                   retain_graph=True,\n",
    "                                   create_graph=True,\n",
    "                                   only_inputs=True)[0]\n",
    "        dydx = dydx.view(dydx.size(0), -1)\n",
    "        dydx_l2norm = torch.sqrt(torch.sum(dydx**2, dim=1))\n",
    "        return torch.mean((dydx_l2norm-1)**2)\n",
    "    \n",
    "    # Resets the gradients on our optimizers\n",
    "    def reset_grad():\n",
    "        g_optimizer.zero_grad()\n",
    "        d_optimizer.zero_grad()\n",
    "    \n",
    "    # Record the time before training starts\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Keep track of best losses\n",
    "    best_d_loss = 1e20\n",
    "    best_d_loss_e = 0\n",
    "    best_g_loss = 1e20\n",
    "    best_g_loss_e = 0\n",
    "    \n",
    "    # Make a progress bar\n",
    "    bar = tqdm(desc=\"GAN Iteration\", total=num_iters + 1, position=2)\n",
    "    \n",
    "    # Iterate over the dataset\n",
    "    for i in range(1, num_iters + 1):\n",
    "        # Move the progress bar forward\n",
    "        bar.update(1)\n",
    "        # =================================================================================== #\n",
    "        #                             1. Preprocess input data                                #\n",
    "        # =================================================================================== #\n",
    "        # Take a batch from the dataset iterator\n",
    "        try:\n",
    "            x_real, label_org = next(data_iter)\n",
    "        # Restart iteration over the dataset iterator when it runs out of batches\n",
    "        except StopIteration:\n",
    "            data_iter = iter(data_loader)\n",
    "            x_real, label_org = next(data_iter)\n",
    "        \n",
    "        # Generate target domain labels randomly.\n",
    "        rand_idx = torch.randperm(label_org.size(0))\n",
    "        label_trg = label_org[rand_idx]\n",
    "        \n",
    "        # Send data to compute device\n",
    "        x_real = x_real.to(device)              # Input images.\n",
    "        c_org = label_org.to(device, copy=True) # Original domain labels.\n",
    "        c_trg = label_trg.to(device, copy=True) # Target domain labels.\n",
    "        label_org = label_org.to(device)        # Labels for computing classification loss.\n",
    "        label_trg = label_trg.to(device)        # Labels for computing classification loss.\n",
    "\n",
    "        # =================================================================================== #\n",
    "        #                             2. Train the discriminator                              #\n",
    "        # =================================================================================== #\n",
    "        # Compute loss with real images.\n",
    "        out_src, out_cls = discriminator(x_real)\n",
    "        d_loss_real = - torch.mean(out_src)\n",
    "        d_loss_cls = classification_loss(out_cls, label_org)\n",
    "\n",
    "        # Compute loss with fake images.\n",
    "        x_fake = generator(x_real, c_trg)\n",
    "        out_src, out_cls = discriminator(x_fake.detach())\n",
    "        d_loss_fake = torch.mean(out_src)\n",
    "\n",
    "        # Compute loss for gradient penalty.\n",
    "        alpha = torch.rand(x_real.size(0), 1, 1, 1).to(device)\n",
    "        x_hat = (alpha * x_real.data + (1 - alpha) * x_fake.data).requires_grad_(True)\n",
    "        out_src, _ = discriminator(x_hat)\n",
    "        d_loss_gp = gradient_penalty(out_src, x_hat)\n",
    "\n",
    "        # Backward and optimize.\n",
    "        d_loss = d_loss_real + d_loss_fake + \\\n",
    "                 lambda_cls * d_loss_cls + \\\n",
    "                 lambda_gp * d_loss_gp\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Store loss values\n",
    "        loss = {}\n",
    "        loss['D/loss_real'] = d_loss_real.item()\n",
    "        loss['D/loss_fake'] = d_loss_fake.item()\n",
    "        loss['D/loss_cls'] = d_loss_cls.item()\n",
    "        loss['D/loss_gp'] = d_loss_gp.item()\n",
    "        loss['D/loss'] = d_loss.item()\n",
    "        \n",
    "        # =================================================================================== #\n",
    "        #                               3. Train the generator                                #\n",
    "        # =================================================================================== #\n",
    "        # If this is a generator iteration, train the generator on the current mini batch\n",
    "        if (i+1) % n_critic == 0:\n",
    "            # Original-to-target domain.\n",
    "            x_fake = generator(x_real, c_trg)\n",
    "            out_src, out_cls = discriminator(x_fake)\n",
    "            g_loss_fake = - torch.mean(out_src)\n",
    "            g_loss_cls = classification_loss(out_cls, label_trg)\n",
    "            \n",
    "            # Measure original-to-target domain perturbation\n",
    "            g_loss_del = torch.mean(torch.abs(x_fake - x_real))\n",
    "            \n",
    "            # Target-to-original domain.\n",
    "            x_reconst = generator(x_fake, c_org)\n",
    "            g_loss_rec = torch.mean(torch.abs(x_real - x_reconst))\n",
    "            \n",
    "            # Backward and optimize.\n",
    "            g_loss = g_loss_fake + lambda_rec * g_loss_rec + lambda_cls * g_loss_cls + lambda_del * g_loss_del\n",
    "            reset_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            # Logging.\n",
    "            loss['G/loss_fake'] = g_loss_fake.item()\n",
    "            loss['G/loss_rec'] = g_loss_rec.item()\n",
    "            loss['G/loss_cls'] = g_loss_cls.item()\n",
    "            loss['G/loss_del'] = g_loss_del.item()\n",
    "            loss['G/loss'] = g_loss.item()\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            # Only perform on generator iterations\n",
    "            # If changes are enough to warrant an update of the best\n",
    "            if best_d_loss - d_loss.item() >= improvement_amount or best_g_loss - g_loss.item() >= improvement_amount:\n",
    "                if best_d_loss - d_loss.item() >= improvement_amount:\n",
    "                    best_d_loss = d_loss.item()\n",
    "                    best_d_loss_e = i\n",
    "                if best_g_loss - g_loss.item() >= improvement_amount:\n",
    "                    best_g_loss = g_loss.item()\n",
    "                    best_g_loss_e = i\n",
    "            # If neither discriminator nor generator loss have improved by some number of epochs\n",
    "            elif (i-best_d_loss_e) > improvement_patience and \\\n",
    "               (i-best_g_loss_e) > improvement_patience:\n",
    "                et = time.time() - start_time\n",
    "                et = str(datetime.timedelta(seconds=et))[:-7]\n",
    "                loss[\"status\"] = \"Exiting early to avoid overfitting\"\n",
    "                bar.set_postfix(loss)\n",
    "                bar.close()\n",
    "                break\n",
    "            if (i+1) % log_step == 0:\n",
    "                bar.set_postfix(loss)\n",
    "        # =================================================================================== #\n",
    "        #                                 4. Miscellaneous                                    #\n",
    "        # =================================================================================== #\n",
    "    bar.close()\n",
    "    # Return the trained discriminator and generator\n",
    "    return (discriminator, generator)\n",
    "def evaluate_discriminator(discriminator, x_tensor, y_true, prefix=None):\n",
    "    \"\"\"\n",
    "    Evaluates the discriminator\n",
    "    :param x: Tensor input\n",
    "    :param y: Numpy output\n",
    "    \"\"\"\n",
    "    if prefix is None:\n",
    "        prefix = \"\"\n",
    "    else:\n",
    "        prefix = f\"{prefix}/\"\n",
    "    # Feed the input through the classifier\n",
    "    _, y_predicted_tensor = discriminator(x_tensor)\n",
    "    y_predicted = np.argmax(y_predicted_tensor.detach().numpy(), axis=1)\n",
    "    # Calculate PR-AUC of the classifier's predictions\n",
    "    pr_auc = average_precision_score(y_true, y_predicted)\n",
    "    # Calculate a confusion matrix\n",
    "    confusion_m = confusion_matrix(y_true, y_predicted)\n",
    "    # Calculate FPR\n",
    "    tn, fp, _, _ = confusion_m.ravel()\n",
    "    fpr = float(fp) / float(fp + tn)\n",
    "    # Accuracy of the classifier's predictions\n",
    "    accuracy = accuracy_score(y_true, y_predicted)\n",
    "    # Collect all metrics into an object\n",
    "    metrics = {\"pr_auc\": pr_auc, \"confusion_matrix\": confusion_m, \"accuracy\": accuracy, \"fpr\": fpr}\n",
    "    # Return metrics\n",
    "    return {f\"{prefix}{key}\": value for key, value in metrics.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, **config):\n",
    "        super(Classifier, self).__init__()\n",
    "        # Get hidden layer size\n",
    "        hidden_layer_size = config.get(\"hidden_layer_size\", 16)\n",
    "        # Hidden layer\n",
    "        self.fc1 = nn.Linear(np.product(input_dim), hidden_layer_size)\n",
    "        # Output layer\n",
    "        self.out = nn.Linear(hidden_layer_size, 1)\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(-2)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return torch.sigmoid(self.out(x))\n",
    "\n",
    "def train_classifier(x, y, **config):\n",
    "    \"\"\"\n",
    "    Trains a basic traffic classifier\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = {}\n",
    "    # Training device\n",
    "    device = torch.device(config.get(\"device\", \"cpu\"))\n",
    "    \n",
    "    # Validation size\n",
    "    validation_size = config.get(\"validation_size\", 0.1)\n",
    "    \n",
    "    # Hyperparameters\n",
    "    batch_size = config.get(\"batch_size\", 16)\n",
    "    lr = config.get(\"lr\", 1e-4)\n",
    "    beta1 = config.get(\"beta1\", 0.5)\n",
    "    beta2 = config.get(\"beta2\", 0.999)\n",
    "    log_step = config.get(\"log_step\", 10)\n",
    "    num_epochs = config.get(\"num_epochs\", 100)\n",
    "    # Early stopping parameters\n",
    "    improvement_patience = config.get(\"improvement_patience\", 5)\n",
    "    improvement_amount = config.get(\"improvement_amount\", 1e-3)\n",
    "\n",
    "    # Find the input dimensions\n",
    "    input_dim = x.shape[-2:]\n",
    "\n",
    "    # Initialize the model\n",
    "    classifier = Classifier(input_dim).to(device)\n",
    "    # Initialize the optimizer\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr, betas=(beta1, beta2))\n",
    "    # Initialize the loss\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Split the dataset\n",
    "    x, x_v, y, y_v = train_test_split(x, y, test_size=validation_size, train_size=None)\n",
    "    \n",
    "    # Convert the training set from numpy to torch\n",
    "    x = torch.from_numpy(x)\n",
    "    y = torch.from_numpy(y).float()\n",
    "    # Convert the validation set from numpy to torch\n",
    "    x_v = torch.from_numpy(x_v)\n",
    "    y_v = torch.from_numpy(y_v).float().view(-1,1)\n",
    "    # Create a dataset from the test training set\n",
    "    dataset = TensorDataset(x, y.view(-1,1))\n",
    "    # Abstract tensor data loading\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    # Keep track of previous validation losses\n",
    "    best_val_loss = 1e20\n",
    "    best_val_loss_e = 0\n",
    "    # Make a progress bar\n",
    "    bar = tqdm(desc=\"Classifier epoch\", total=num_epochs, position=3)\n",
    "    # Iterate for some number of epochs\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in data_loader:\n",
    "            # Separate data in the batch\n",
    "            inputs, labels = batch\n",
    "            # Send data to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = classifier(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Accumulate loss\n",
    "            epoch_loss += loss.item()\n",
    "        # Calculate validation loss\n",
    "        outputs_v = classifier(x_v)\n",
    "        loss_v = criterion(outputs_v, y_v).item()\n",
    "        # Log if on a log epoch\n",
    "        if epoch % log_step == 0:\n",
    "            loss = {'loss': epoch_loss / x.shape[0], 'val_loss': loss_v / x_v.shape[0]}\n",
    "            bar.set_postfix(loss)\n",
    "        # If validation loss improvement is enough to be considered an upgrade, log it\n",
    "        if best_val_loss - loss_v >= improvement_amount:\n",
    "            #print(f'{epoch}: class loss update {best_val_loss} to {loss_v}')\n",
    "            best_val_loss = loss_v\n",
    "            best_val_loss_e = epoch\n",
    "        # If it has been some number of epochs since the last loss improvement, quit\n",
    "        elif (epoch - best_val_loss_e) > improvement_patience:\n",
    "            loss = {'loss': epoch_loss / x.shape[0], 'val_loss': loss_v / x_v.shape[0], 'status': \"Exiting early to avoid overfitting\"}\n",
    "            bar.set_postfix(loss)\n",
    "            bar.close()\n",
    "            # Because we are in a nested loop, we must return\n",
    "            return classifier\n",
    "        # Reset epoch loss\n",
    "        epoch_loss = 0.0\n",
    "        # Update bar\n",
    "        bar.update()\n",
    "    bar.close()\n",
    "    return classifier\n",
    "def evaluate_classifier(classifier, x_tensor, y_true, prefix=None):\n",
    "    \"\"\"\n",
    "    Evaluates a classifier on a dataset\n",
    "    :param x: Tensor input\n",
    "    :param y: Numpy output\n",
    "    \"\"\"\n",
    "    # Set the prefix\n",
    "    if prefix is None:\n",
    "        prefix = \"\"\n",
    "    else:\n",
    "        prefix = f\"{prefix}/\"\n",
    "    # Feed the input through the classifier\n",
    "    y_predicted_tensor = classifier(x_tensor)\n",
    "    y_predicted = y_predicted_tensor.detach().numpy()\n",
    "    # Calculate PR-AUC of the classifier's predictions\n",
    "    pr_auc = average_precision_score(y_true, y_predicted)\n",
    "    # Create a version of the predictions that is absolute\n",
    "    # by rounding to the nearest integer\n",
    "    y_predicted_abs = np.rint(y_predicted)\n",
    "    # Calculate a confusion matrix\n",
    "    confusion_m = confusion_matrix(y_true, y_predicted_abs)\n",
    "    # Calculate FPR\n",
    "    tn, fp, _, _ = confusion_m.ravel()\n",
    "    fpr = float(fp) / float(fp + tn)\n",
    "    # Accuracy of the classifier's predictions\n",
    "    accuracy = accuracy_score(y_true, y_predicted_abs)\n",
    "    # Collect all metrics into an object\n",
    "    metrics = {\"pr_auc\": pr_auc, \"confusion_matrix\": confusion_m, \"accuracy\": accuracy, \"fpr\": fpr}\n",
    "    # Return metrics\n",
    "    return {f\"{prefix}{key}\": value for key, value in metrics.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dt(x, y, **config):\n",
    "    # Extract random state from config\n",
    "    random_state = config.get(\"random_state\", None)\n",
    "    # Build a decision tree\n",
    "    dt = DecisionTreeClassifier(random_state=random_state)\n",
    "    # Flatten the input\n",
    "    x_flat = x.reshape(x.shape[0], np.product(x.shape[1:]))\n",
    "    # Train the decision tree on the given data\n",
    "    dt.fit(x_flat, y)\n",
    "    # Return the model\n",
    "    return dt\n",
    "\n",
    "def evaluate_dt(dt, x, y_true, prefix=None):\n",
    "    \"\"\"\n",
    "    Evaluates a classifier on a dataset\n",
    "    :param x: Tensor input\n",
    "    :param y: Numpy output\n",
    "    \"\"\"\n",
    "    # Set the prefix\n",
    "    if prefix is None:\n",
    "        prefix = \"\"\n",
    "    else:\n",
    "        prefix = f\"{prefix}/\"\n",
    "    # Feed the input through the classifier\n",
    "    y_predicted = dt.predict(x.reshape(x.shape[0], np.product(x.shape[1:])))\n",
    "    # Calculate PR-AUC of the classifier's predictions\n",
    "    pr_auc = average_precision_score(y_true, y_predicted)\n",
    "    # Calculate a confusion matrix\n",
    "    confusion_m = confusion_matrix(y_true, y_predicted)\n",
    "    # Calculate FPR\n",
    "    tn, fp, _, _ = confusion_m.ravel()\n",
    "    fpr = float(fp) / float(fp + tn)\n",
    "    # Accuracy of the classifier's predictions\n",
    "    accuracy = accuracy_score(y_true, y_predicted)\n",
    "    # Collect all metrics into an object\n",
    "    metrics = {\"pr_auc\": pr_auc, \"confusion_matrix\": confusion_m, \"accuracy\": accuracy, \"fpr\": fpr}\n",
    "    # Return metrics\n",
    "    return {f\"{prefix}{key}\": value for key, value in metrics.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES=2\n",
    "def combine_datasets(normal_data, tor_data):\n",
    "    # Create labels for the normal and tor datasets\n",
    "    y_normal = np.repeat(0, normal_data.shape[0])\n",
    "    y_tor = np.repeat(1, tor_data.shape[0])\n",
    "    # Concatenate the normal and tor datasets into one large dataset\n",
    "    x = np.concatenate((normal_data, tor_data))\n",
    "    y = np.concatenate((y_normal, y_tor))\n",
    "    # Print some info about the dataset\n",
    "    display(Markdown(f\"**Dataset input shape**: {x.shape}\"))\n",
    "    display(Markdown(f\"**Dataset output shape**: {y.shape}\"))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(cm, labels):\n",
    "    for truth, row in enumerate(cm):\n",
    "        for pred, freq in enumerate(row):\n",
    "            print(\"Predicted {} but got {}: {}\".format(labels[truth],labels[pred],freq))\n",
    "\n",
    "def split_proportionally(datasets, proportions, shuffle=True, random_state=None):\n",
    "    \"\"\"\n",
    "    Splits datasets into given proportions and yields each permutation of\n",
    "    these splits\n",
    "    :param datasets list(np.array): Datasets to split\n",
    "    :param proportions list(float): Proportions to use for splitting\n",
    "    :param shuffle: Whether to shuffle the datasets before splitting\n",
    "    :param random_state: Used to seed the shuffle\n",
    "    :yields permutations of the given dataset splits:\n",
    "    \"\"\"\n",
    "    # Ensure there is at least one dataset\n",
    "    if len(datasets) == 0:\n",
    "        raise Exception(\"Must provide at least one dataset\")\n",
    "    # Ensure all datasets have the same first dimension\n",
    "    dataset_len = datasets[0].shape[0]\n",
    "    for dataset in datasets[1:]:\n",
    "        if dataset.shape[0] != dataset_len:\n",
    "            raise Exception(\"All datasets must be of equal length\")\n",
    "    # Ensure there is at least 2 proportins\n",
    "    if len(proportions) < 2:\n",
    "        raise Exception(\"Not enough proportion values\")\n",
    "    # Shuffle once, initially if told to\n",
    "    if shuffle:\n",
    "        datasets = sklearn_utils.shuffle(*datasets, random_state=random_state)\n",
    "    # Start iterating over permutations\n",
    "    for permutation in permutations(range(len(proportions))):\n",
    "        # Create proportions from the permutation\n",
    "        cur_proportions = [proportions[i] for i in permutation]\n",
    "        # Start with the full dataset\n",
    "        dataset_remainders = datasets\n",
    "        # Accumulate split datasets\n",
    "        # dataset_0_split_0, dataset_1_split_0, dataset_1_split_0, dataset_1_split_1, ...\n",
    "        split_datasets = []\n",
    "        # Iterate with proportions until the end\n",
    "        for idx, proportion in enumerate(cur_proportions[:-1]):\n",
    "            # Determine the current proportions fraction of the remaining dataset\n",
    "            cur_fraction = float(proportion) / (proportion + sum(cur_proportions[idx + 1:]))\n",
    "            # After each split, we get a new set of remainders\n",
    "            new_remainders = []\n",
    "            # Split each dataset\n",
    "            for dataset in dataset_remainders:\n",
    "                # Perform the split using sklearn\n",
    "                split_dataset, remainder_dataset = train_test_split(dataset, train_size=cur_fraction, test_size=None, shuffle=False)\n",
    "                # Split dataset goes onto the list\n",
    "                split_datasets.append(split_dataset)\n",
    "                # Remainder dataset goes into the remainders\n",
    "                new_remainders.append(remainder_dataset)\n",
    "            # Replace remainders\n",
    "            dataset_remainders = new_remainders\n",
    "        # Add the remaining remainders to the split list\n",
    "        split_datasets += dataset_remainders\n",
    "        # The datasets need to be rearranged\n",
    "        rearranged_split_datasets = []\n",
    "        for i in range(len(proportions)):\n",
    "            # The new index is the position where the permutation has placed it\n",
    "            i = permutation.index(i)\n",
    "            for j in range(len(datasets)):\n",
    "                rearranged_split_datasets.append(split_datasets[i * len(datasets) + j])\n",
    "        # Yield the split datasets\n",
    "        yield tuple(rearranged_split_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(x, y, draw_figure=False, figure_size=None, seed=None):\n",
    "    device = \"cpu\"\n",
    "    # Common config to neural nets\n",
    "    nn_config = {\n",
    "        # Device to process on\n",
    "        'device': device,\n",
    "        # Size of minibatches\n",
    "        'batch_size': 16,\n",
    "        # Learning rate\n",
    "        'lr': 1e-4,\n",
    "        # Used for optimizer\n",
    "        'beta1': 0.5,\n",
    "        'beta2:': 0.99,\n",
    "    }\n",
    "\n",
    "    # Config options for training the GAN\n",
    "    gan_config = {\n",
    "        'num_iters': 40000,\n",
    "        #'num_iters': 400,\n",
    "        'log_step': 100,\n",
    "        \"improvement_patience\": 2000,\n",
    "        \"improvement_amount\": 1e-4,\n",
    "        \"g_lr\": nn_config['lr'],\n",
    "        \"d_lr\": nn_config['lr'],\n",
    "        'lambda_cls': 1,\n",
    "        'lambda_rec': 10,\n",
    "        'lambda_gp': 10,\n",
    "        'lambda_del': 10,\n",
    "        'n_critic': 5,\n",
    "    }\n",
    "    # Config options for training the NN classifier\n",
    "    classifier_config = {\n",
    "        'num_epochs': 1000,\n",
    "        'log_step': 5,\n",
    "        \"improvement_patience\": 10,\n",
    "        \"improvement_amount\": 1e-2,\n",
    "        \"batch_size\": 16,\n",
    "    }\n",
    "\n",
    "    # Add common config to gan and classifier config, allowing them to override\n",
    "    # Start scope\n",
    "    if True:\n",
    "        # Copy and override\n",
    "        nn_config_c = nn_config.copy()\n",
    "        nn_config_c.update(gan_config)\n",
    "        # Replace\n",
    "        gan_config = nn_config_c\n",
    "        # Copy and override\n",
    "        nn_config_c = nn_config.copy()\n",
    "        nn_config_c.update(classifier_config)\n",
    "        # Replace\n",
    "        classifier_config = nn_config_c\n",
    "\n",
    "    # Config options for training the DT\n",
    "    dt_config = {\n",
    "        'random_state': seed,\n",
    "    }\n",
    "\n",
    "\n",
    "    # Stores metrics for each fold\n",
    "    fold_metrics = []\n",
    "    # Split the dataset 50-30-20\n",
    "    # 50% to train the GAN\n",
    "    # 30% to train the classifier\n",
    "    # 20% to test the classifier\n",
    "    for x_train, y_train, x_cls_train, y_cls_train, x_cls_test, y_cls_test in tqdm(split_proportionally((x,y), [30,20,50], random_state=seed), total=6, position=1, desc=\"Fold\"):\n",
    "        # Stores fold metrics\n",
    "        cur_fold_metrics = {}\n",
    "        # Train the GAN\n",
    "        discriminator, generator = train_gan(x_train, y_train, **gan_config)\n",
    "\n",
    "        # Evaluate the discriminator\n",
    "        #dsc_fold_metrics = {}\n",
    "        #dsc_fold_metrics.update(evaluate_discriminator(discriminator, torch.from_numpy(x_cls_test), y_cls_test, prefix=\"pre_transform\"))\n",
    "        #dsc_fold_metrics.update(evaluate_discriminator(discriminator, generator(torch.from_numpy(x_cls_test), torch.from_numpy(1 - y_cls_test)), y_cls_test, prefix=\"post_transform\"))\n",
    "        #dsc_fold_metrics.update(evaluate_discriminator(discriminator, generator(torch.from_numpy(x_cls_test), torch.from_numpy(1 - y_cls_test)), 1 - y_cls_test, prefix=\"post_transform/flipped\"))\n",
    "        # Add discriminator metrics to the main set\n",
    "        #cur_fold_metrics.update({f\"discriminator/{key}\": value for key, value in dsc_fold_metrics.items()})\n",
    "\n",
    "        # Train a neural net classifier\n",
    "        classifier = train_classifier(x_cls_train, y_cls_train, **classifier_config)\n",
    "\n",
    "        # Convert the test set from numpy to torch\n",
    "        x_cls_test = torch.from_numpy(x_cls_test)\n",
    "        # Store a copy of the labels for later\n",
    "        y_cls_test_np = y_cls_test\n",
    "        y_cls_test = torch.from_numpy(y_cls_test_np)\n",
    "        # Create a set of labels where the class is flipped for each entry in the test set\n",
    "        y_cls_test_flipped = 1 - y_cls_test\n",
    "        # Transform the test set using the generator\n",
    "        x_cls_test_transformed = generator(x_cls_test, y_cls_test_flipped)\n",
    "\n",
    "        # Evaluate the NN\n",
    "        nn_fold_metrics = {}\n",
    "        # Evaluate the NN on a test set\n",
    "        nn_fold_metrics.update(evaluate_classifier(classifier, x_cls_test, y_cls_test_np, prefix=\"pre_transform\"))\n",
    "        # Evaluate the NN's efficacy in determining the original class of the modified traffic\n",
    "        nn_fold_metrics.update(evaluate_classifier(classifier, x_cls_test_transformed, y_cls_test_np, prefix=\"post_transform\"))\n",
    "        # Evaluate the NN's efficacy in determining the opposite class of the modified traffic\n",
    "        #nn_fold_metrics.update(evaluate_classifier(classifier, x_cls_test_transformed, y_cls_test_flipped.detach().numpy(), prefix=\"post_transform/flipped\"))\n",
    "        # Add NN metrics to the main set\n",
    "        cur_fold_metrics.update({f\"neural_network/{key}\": value for key, value in nn_fold_metrics.items()})\n",
    "\n",
    "        # Split train data\n",
    "        x_cls_train1, x_cls_train2, y_cls_train1, y_cls_train2 = train_test_split(x_cls_train, y_cls_train, train_size=0.5, random_state=seed, shuffle=False)\n",
    "        # Get flipped labels on one half\n",
    "        y_cls_train2_flipped = 1 - y_cls_train2\n",
    "        # Transform one half of the training set\n",
    "        x_cls_train2 = generator(torch.from_numpy(x_cls_train2), torch.from_numpy(y_cls_train2_flipped)).detach().numpy()\n",
    "        # Concatenate the modified and unmodified dataset\n",
    "        x_cls_train_modify = np.concatenate((x_cls_train1, x_cls_train2))\n",
    "        # y_cls_train is still considered the same since we want to train on \"original\" class\n",
    "        # But it is modified by the train test split\n",
    "        y_cls_train_modify = np.concatenate((y_cls_train1, y_cls_train2))\n",
    "        # Train a neural net classifier over the half modified data\n",
    "        classifier_mod = train_classifier(x_cls_train_modify, y_cls_train_modify, **classifier_config)\n",
    "        # Evaluate the NN\n",
    "        nn_mod_fold_metrics = {}\n",
    "        # Evaluate the NN on a test set\n",
    "        nn_mod_fold_metrics.update(evaluate_classifier(classifier_mod, x_cls_test, y_cls_test_np, prefix=\"pre_transform\"))\n",
    "        # Evaluate the NN's efficacy in determining the original class of the modified traffic\n",
    "        nn_mod_fold_metrics.update(evaluate_classifier(classifier_mod, x_cls_test_transformed, y_cls_test_np, prefix=\"post_transform\"))\n",
    "        # Evaluate the NN's efficacy in determining the opposite class of the modified traffic\n",
    "        #nn_fold_metrics.update(evaluate_classifier(classifier, x_cls_test_transformed, y_cls_test_flipped.detach().numpy(), prefix=\"post_transform/flipped\"))\n",
    "        # Add NN metrics to the main set\n",
    "        cur_fold_metrics.update({f\"neural_network_mod/{key}\": value for key, value in nn_mod_fold_metrics.items()})\n",
    "        \n",
    "        # Train a random forest classifier\n",
    "        dt = train_dt(x_cls_train, y_cls_train, **dt_config)\n",
    "\n",
    "        # Evaluate the random forest\n",
    "        dt_fold_metrics = {}\n",
    "        # Evaluate the random forest on a test set\n",
    "        dt_fold_metrics.update(evaluate_dt(dt, x_cls_test, y_cls_test, prefix=\"pre_transform\"))\n",
    "        # Evaluate the random forest's efficacy in determining the original class of the modified traffic\n",
    "        dt_fold_metrics.update(evaluate_dt(dt, x_cls_test_transformed.detach().numpy(), y_cls_test, prefix=\"post_transform\"))\n",
    "        # Evaluate the random forest's efficacy in determining the opposite class of the modified traffic\n",
    "        #rf_fold_metrics.update(evaluate_rf(rf, x_cls_test_transformed.detach().numpy(), y_cls_test_flipped.detach().numpy(), prefix=\"post_transform/flipped\"))\n",
    "        # Add RF metrics to the main set\n",
    "        cur_fold_metrics.update({f\"decision_tree/{key}\": value for key, value in dt_fold_metrics.items()})\n",
    "\n",
    "        # Record all of this fold's metrics\n",
    "        fold_metrics.append(cur_fold_metrics)\n",
    "        #print(cur_fold_metrics)\n",
    "\n",
    "    # Average metrics from each fold\n",
    "    avg_metrics = {}\n",
    "    for key in fold_metrics[0].keys():\n",
    "            avg_metrics[key] = np.mean([fold[key] for fold in fold_metrics], axis=0)\n",
    "\n",
    "    return (avg_metrics, fold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_stats(avg_metrics):\n",
    "    def print_stats(*kws):\n",
    "        for key, value in avg_metrics.items():\n",
    "            if all(map(lambda kw: kw in key, kws)):\n",
    "                if 'confusion' not in key:\n",
    "                    print(\"{}:  {:0.5f}\".format(key, np.round(value, 5)))\n",
    "                else:\n",
    "                    print(key)\n",
    "                    print(value.astype(np.int))\n",
    "                    pass\n",
    "    for metric in ['pr_auc','fpr', 'accuracy', 'confusion']:\n",
    "        for classifier in ['neural_network','decision_tree','discriminator']:\n",
    "            print_stats(classifier, metric)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset, InsetPosition\n",
    "\n",
    "def generate_figures_mod(normal_data, tor_data, figure_dir, figure_size):\n",
    "    device = \"cpu\"\n",
    "    # Common config to neural nets\n",
    "    nn_config = {\n",
    "        # Device to process on\n",
    "        'device': device,\n",
    "        # Size of minibatches\n",
    "        'batch_size': 16,\n",
    "        # Learning rate\n",
    "        'lr': 1e-4,\n",
    "        # Used for optimizer\n",
    "        'beta1': 0.5,\n",
    "        'beta2:': 0.99,\n",
    "    }\n",
    "\n",
    "    # Config options for training the GAN\n",
    "    gan_config = {\n",
    "        'num_iters': 40000,\n",
    "        #'num_iters': 400,\n",
    "        'log_step': 100,\n",
    "        \"improvement_patience\": 2000,\n",
    "        \"improvement_amount\": 1e-4,\n",
    "        \"g_lr\": nn_config['lr'],\n",
    "        \"d_lr\": nn_config['lr'],\n",
    "        'lambda_cls': 1,\n",
    "        'lambda_rec': 10,\n",
    "        'lambda_gp': 10,\n",
    "        'lambda_del': 10,\n",
    "        'n_critic': 5,\n",
    "    }\n",
    "\n",
    "    # Add common config to gan and classifier config, allowing them to override\n",
    "    # Start scope\n",
    "    if True:\n",
    "        # Copy and override\n",
    "        nn_config_c = nn_config.copy()\n",
    "        nn_config_c.update(gan_config)\n",
    "        # Replace\n",
    "        gan_config = nn_config_c\n",
    "    # Combine the datasets\n",
    "    x, y = combine_datasets(normal_data, tor_data)\n",
    "    \n",
    "    # Train a transformer\n",
    "    discriminator, transformer = train_gan(x, y, **gan_config)\n",
    "    \n",
    "    # Modify Meek traffic using the transformer\n",
    "    meek_mod_data  = transformer(torch.from_numpy(tor_data).to(device), torch.from_numpy(np.repeat(0, tor_data.shape[0])).to(device)).cpu().detach().numpy()\n",
    "    # masked_normal_data = generator(torch.from_numpy(normal_data).to(device), torch.from_numpy(np.repeat(1, normal_data.shape[0])).to(device)).cpu().detach().numpy()\n",
    "    # Draw the gan results\n",
    "    sns.set()\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.rcParams.update({'savefig.dpi': 1200})\n",
    "    ps_bins = list(map(str, list(range(0,100+1, 10)) + list(range(200,1000+1,100)) + list(range(2000,10000+1,1000)) + ['∞']))\n",
    "    ia_bins = list(map(str, list(range(0,10+1)) + list(range(20,100+1,10)) + list(range(200,1000+1,100)) + ['∞']))\n",
    "    # Average fields for each dataset and feature\n",
    "    data = {\n",
    "        \"x\": [i + 0.5 for i in range(29)],\n",
    "        \"meek_ps\":      tor_data[:,0,:].mean(axis=0),\n",
    "        \"meek_mod_ps\":  meek_mod_data[:,0,:].mean(axis=0),\n",
    "        \"normal_ps\":    normal_data[:,0,:].mean(axis=0),\n",
    "        \"meek_iaf\":     tor_data[:,1,:].mean(axis=0),\n",
    "        \"meek_mod_iaf\": meek_mod_data[:,1,:].mean(axis=0),\n",
    "        \"normal_iaf\" :  normal_data[:,1,:].mean(axis=0),\n",
    "        \"meek_iat\":     tor_data[:,2,:].mean(axis=0),\n",
    "        \"meek_mod_iat\": meek_mod_data[:,1,:].mean(axis=0),\n",
    "        \"normal_iat\":   normal_data[:,2,:].mean(axis=0),\n",
    "    }\n",
    "    # Start plotting packet sizes\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    #sns.lineplot(\"x\", \"tor_ps\", label=\"Tor\", data=data)\n",
    "    ax = sns.lineplot(\"x\", \"meek_mod_ps\", label=\"Meek (modified)\", data=data)\n",
    "    sns.lineplot(\"x\", \"normal_ps\", label=\"HTTPS\", data=data)\n",
    "    ax.set_xlabel(\"TCP Payload Length (bytes)\", fontsize=28)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=28)\n",
    "    ax.set_xticks(range(30))\n",
    "    ax.set_xticklabels(ps_bins, rotation=90)\n",
    "    ax.tick_params(labelsize=22)\n",
    "    ax.legend()\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='26') # for legend text\n",
    "    #axins = zoomed_inset_axes(ax, zoom=2, loc='upper center')\n",
    "    #axins.set_xlim(4, 9) # apply the x-limits\n",
    "    #axins.set_ylim(0, 0.1) # apply the y-limits\n",
    "    #axins.set_xticks(range(30))\n",
    "    #axins.set_xticklabels(ps_bins, rotation=90)\n",
    "    #plt.xticks(visible=False)\n",
    "    #plt.yticks(visible=False)\n",
    "    #mark_inset(ax, axins, loc1=2, loc2=3, fc=\"none\", ec=\"0.5\")\n",
    "    #sns.lineplot(\"x\", \"meek_mod_ps\", label=\"Meek (modified)\", data=data, ax=axins)\n",
    "    #sns.lineplot(\"x\", \"normal_ps\", label=\"Normal\", data=data, ax=axins)\n",
    "    fig.savefig(figure_dir / 'modified-features-packet-size.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Start plotting interarrival from client\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    #sns.lineplot(\"x\", \"tor_iaf\", label=\"Tor\", data=data)\n",
    "    ax = sns.lineplot(\"x\", \"meek_mod_iaf\", label=\"Meek (modified)\", data=data)\n",
    "    sns.lineplot(\"x\", \"normal_iaf\", label=\"HTTPS\", data=data)\n",
    "    ax.set_xlabel(\"Inter-arrival time from client (ms)\", fontsize=28)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=28)\n",
    "    ax.set_xticks(range(30))\n",
    "    ax.set_xticklabels(ia_bins, rotation=90)\n",
    "    ax.tick_params(labelsize=22)\n",
    "    ax.legend()\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='26') # for legend text\n",
    "    fig.savefig(figure_dir / 'modified-features-iaf.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # Start plotting interarrival to client\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    #sns.lineplot(\"x\", \"tor_iat\", label=\"Tor\", data=data)\n",
    "    ax = sns.lineplot(\"x\", \"meek_mod_iat\", label=\"Meek (modified)\", data=data)\n",
    "    sns.lineplot(\"x\", \"normal_iat\", label=\"HTTPS\", data=data)\n",
    "    ax.set_xlabel(\"Inter-arrival time to client (ms)\", fontsize=28)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=28)\n",
    "    ax.set_xticks(range(30))\n",
    "    ax.set_xticklabels(ia_bins, rotation=90)\n",
    "    ax.tick_params(labelsize=22)\n",
    "    ax.legend()\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='26') # for legend text\n",
    "    fig.savefig(figure_dir / 'modified-features-iat.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_SIZE=(12,8)\n",
    "normal_data, tor_data = load_data(H_ROOT)\n",
    "generate_figures(normal_data, tor_data, FIGURE_DIR, FIGURE_SIZE)\n",
    "generate_figures_mod(normal_data, tor_data, FIGURE_DIR, FIGURE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_ROOT = Path('/mnt/data/pcap_data/blake/output-2019-02-25-01')\n",
    "A_ROOT = Path('/mnt/data/pcap_data/aws/output-2019-02-23-01')\n",
    "U_ROOT = Path('/mnt/data/pcap_data/patchouli/output-2019-03-29-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the RNGs to ensure consistency\n",
    "seed = 100\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "ds_metrics = []\n",
    "ds_all_metrics = []\n",
    "\n",
    "train_start_time = time.time()\n",
    "for dataset in (H_ROOT, U_ROOT, A_ROOT):\n",
    "    display(Markdown(f\"# Dataset {dataset}\"))\n",
    "    normal_data, tor_data = load_data(dataset)\n",
    "    x, y = combine_datasets(normal_data, tor_data)\n",
    "    avg_metrics, fold_metrics = train_and_evaluate(x, y, seed=seed)\n",
    "    print_all_stats(avg_metrics)\n",
    "    ds_metrics.append(avg_metrics)\n",
    "    ds_all_metrics += fold_metrics\n",
    "train_duration = time.time() - train_start_time\n",
    "print(f\"Experiments completed after {train_duration} seconds\")\n",
    "ds_avg_metrics = {}\n",
    "for key in ds_metrics[0].keys():\n",
    "    ds_avg_metrics[key] = np.mean([fold[key] for fold in ds_metrics], axis=0)\n",
    "print()\n",
    "display(Markdown(\"# Average\"))\n",
    "print_all_stats(ds_avg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_all_stats(ds_avg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = []\n",
    "modified = []\n",
    "for ds_metric in ds_all_metrics:\n",
    "    orig.append(ds_metric['discriminator/pre_transform/pr_auc'])\n",
    "    modified.append(ds_metric['discriminator/post_transform/pr_auc'])\n",
    "from scipy.stats import wilcoxon\n",
    "wilcoxon(orig, modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
